<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Spark学习总结," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="1. Spark SQL数据加载和保存Spark SQL重要是操作DataFrame，DataFrame本身提供了save和load的操作。
Load：可以创建DataFrame。
Save：把DataFrame中的数据保存到文件或者说与具体的格式来指明我们要读取的文件的类型以及与具体的格式来指出我们要输出的文件是什么类型。">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark学习笔记——Spark SQL的操作实例">
<meta property="og:url" content="http://yoursite.com/2017/03/05/Spark/sparksql/index.html">
<meta property="og:site_name" content="Andone1cc">
<meta property="og:description" content="1. Spark SQL数据加载和保存Spark SQL重要是操作DataFrame，DataFrame本身提供了save和load的操作。
Load：可以创建DataFrame。
Save：把DataFrame中的数据保存到文件或者说与具体的格式来指明我们要读取的文件的类型以及与具体的格式来指出我们要输出的文件是什么类型。">
<meta property="og:image" content="http://img.blog.csdn.net/20160418122518845">
<meta property="og:image" content="http://a3.qpic.cn/psb?/V12DoSDy3E1yI8/t3ehiliZd3REbzq7vvCudql8zJ1MNYt4xmcPc*Wdoys!/b/dB8BAAAAAAAA&bo=pgL1AAAAAAADB3M!&rf=viewer_4">
<meta property="og:updated_time" content="2017-03-05T07:31:55.282Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark学习笔记——Spark SQL的操作实例">
<meta name="twitter:description" content="1. Spark SQL数据加载和保存Spark SQL重要是操作DataFrame，DataFrame本身提供了save和load的操作。
Load：可以创建DataFrame。
Save：把DataFrame中的数据保存到文件或者说与具体的格式来指明我们要读取的文件的类型以及与具体的格式来指出我们要输出的文件是什么类型。">
<meta name="twitter:image" content="http://img.blog.csdn.net/20160418122518845">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/03/05/Spark/sparksql/"/>





  <title> Spark学习笔记——Spark SQL的操作实例 | Andone1cc </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Andone1cc</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一个有梦想的CS小白</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/05/Spark/sparksql/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="QDU-scc">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andone1cc">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Spark学习笔记——Spark SQL的操作实例
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-05T11:17:51+08:00">
                2017-03-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/05/Spark/sparksql/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/05/Spark/sparksql/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="1-Spark-SQL数据加载和保存"><a href="#1-Spark-SQL数据加载和保存" class="headerlink" title="1. Spark SQL数据加载和保存"></a>1. Spark SQL数据加载和保存</h3><p>Spark SQL重要是操作DataFrame，DataFrame本身提供了save和load的操作。</p>
<p>Load：可以创建DataFrame。</p>
<p>Save：把DataFrame中的数据保存到文件或者说与具体的格式来指明我们要读取的文件的类型以及与具体的格式来指出我们要输出的文件是什么类型。</p>
<a id="more"></a>
<p>1) Spark SQL读写数据代码实战：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkSQLLoadSaveOps</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">"local"</span>)</div><div class="line">                .setAppName(<span class="string">"SparkSQLLoadSaveOps"</span>)</div><div class="line">                .set(<span class="string">"spark.testing.memory"</span>, <span class="string">"2147480000"</span>);</div><div class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</div><div class="line">        SQLContext sqlContext = <span class="keyword">new</span> SQLContext(sc);</div><div class="line">        <span class="comment">/**</span></div><div class="line">         * read()是DataFrameReader类型，load可以将数据读取出来</div><div class="line">         */</div><div class="line">       <span class="comment">/* DataFrame peopleDF = sqlContext.read().json("people.json");</span></div><div class="line">        peopleDF.write().save("people");*/</div><div class="line">        DataFrame peopleDF = sqlContext.read().format(<span class="string">"json"</span>).load</div><div class="line">                (<span class="string">"hdfs://node02:8020/people.json"</span>);</div><div class="line">        peopleDF.show();</div><div class="line">        <span class="comment">/**</span></div><div class="line">         * 直接对DataFrame进行操作</div><div class="line">         * Json: 是一种自解释的格式，读取Json的时候怎么判断其是什么格式？</div><div class="line">         * 通过扫描整个Json。扫描之后才会知道元数据</div><div class="line">         */</div><div class="line">        <span class="comment">//通过mode来指定输出文件的是append。创建新文件来追加文件</span></div><div class="line">        peopleDF.select(<span class="string">"name"</span>).write().mode(SaveMode.Append).save</div><div class="line">                (<span class="string">"/user/personNames"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>2) 读取过程源码分析</p>
<blockquote>
<p>1、read方法返回DataFrameReader，用于读取数据,在SQLContext.Scala中：</p>
</blockquote>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * :: Experimental ::</div><div class="line"> * Returns a [[DataFrameReader]] that can be used to read data in as a [[DataFrame]].</div><div class="line"> * &#123;&#123;&#123;</div><div class="line"> *   sqlContext.read.parquet("/path/to/file.parquet")</div><div class="line"> *   sqlContext.read.schema(schema).json("/path/to/file.json")</div><div class="line"> * &#125;&#125;&#125;</div><div class="line"> *</div><div class="line"> * @group genericdata</div><div class="line"> * @since 1.4.0</div><div class="line"> */</div><div class="line"><span class="meta">@Experimental</span></div><div class="line"><span class="comment">//创建DataFrameReader实例，获得了DataFrameReader引用</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>: <span class="type">DataFrameReader</span> = <span class="keyword">new</span> <span class="type">DataFrameReader</span>(<span class="keyword">this</span>)</div></pre></td></tr></table></figure>
</code></pre><blockquote>
<p>2、 然后再调用DataFrameReader类中的format，指出读取文件的格式</p>
</blockquote>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Specifies the input data source format.</div><div class="line">   *</div><div class="line">   * @since 1.4.0</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">format</span></span>(source: <span class="type">String</span>): <span class="type">DataFrameReader</span> = &#123;</div><div class="line">    <span class="keyword">this</span>.source = source</div><div class="line">    <span class="keyword">this</span></div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</code></pre><blockquote>
<p>3、通过DataFrameReader中load方法通过路径把传入过来的输入变成DataFrame</p>
</blockquote>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">  * Loads input in as a [[DataFrame]], for data sources </div><div class="line">  * that require a path (e.g. data backed by</div><div class="line">  * a local or distributed file system).</div><div class="line">  *</div><div class="line">  * @since 1.4.0</div><div class="line">  */</div><div class="line"> <span class="comment">// <span class="doctag">TODO:</span> Remove this one in Spark 2.0.</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">load</span></span>(path: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</div><div class="line">   option(<span class="string">"path"</span>, path).load()</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
</code></pre><p>至此，数据的读取工作就完成了，下面就对DataFrame进行操作。<br>下面就是写操作。</p>
<p>3） 写入过程分析</p>
<blockquote>
<p>1、调用DataFrame中select函数进行队列筛选</p>
</blockquote>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Selects a set of columns. This is a variant of `select` </div><div class="line">   * that can only select</div><div class="line">   * existing columns using column names (i.e. </div><div class="line">   * cannot construct expressions).</div><div class="line">   *</div><div class="line">   * &#123;&#123;&#123;</div><div class="line">   *   // The following two are equivalent:</div><div class="line">   *   df.select("colA", "colB")</div><div class="line">   *   df.select($"colA", $"colB")</div><div class="line">   * &#125;&#125;&#125;</div><div class="line">   * @group dfops</div><div class="line">   * @since 1.3.0</div><div class="line">   */</div><div class="line">  <span class="meta">@scala</span>.annotation.varargs</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">select</span></span>(col: <span class="type">String</span>, cols: <span class="type">String</span>*): <span class="type">DataFrame</span> =</div><div class="line">	 select((col +: cols).map(<span class="type">Column</span>(_)) : _*)</div></pre></td></tr></table></figure>
</code></pre><blockquote>
<p>2.然后通过write将结果写入到外部存储系统中</p>
</blockquote>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * :: Experimental ::</div><div class="line">   * Interface for saving the content of the [[DataFrame]] </div><div class="line">   * out into external storage.</div><div class="line">   *</div><div class="line">   * @group output</div><div class="line">   * @since 1.4.0</div><div class="line">   */</div><div class="line">  <span class="meta">@Experimental</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">write</span></span>: <span class="type">DataFrameWriter</span> = <span class="keyword">new</span> <span class="type">DataFrameWriter</span>(<span class="keyword">this</span>)</div></pre></td></tr></table></figure>
</code></pre><blockquote>
<p>3.在保持文件的时候mode指定追加文件的方式</p>
</blockquote>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Specifies the behavior when data or table already exists. Options include:</div><div class="line">    * Overwrite是覆盖</div><div class="line">   *   - `SaveMode.Overwrite`: overwrite the existing data.</div><div class="line">    *   //创建新的文件然后追加</div><div class="line">   *   - `SaveMode.Append`: append the data.</div><div class="line">   *   - `SaveMode.Ignore`: ignore the operation (i.e. no-op).</div><div class="line">   *   - `SaveMode.ErrorIfExists`: default option, throw an exception at runtime.</div><div class="line">   *</div><div class="line">   * @since 1.4.0</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">mode</span></span>(saveMode: <span class="type">SaveMode</span>): <span class="type">DataFrameWriter</span> = &#123;</div><div class="line">    <span class="keyword">this</span>.mode = saveMode</div><div class="line">    <span class="keyword">this</span></div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</code></pre><blockquote>
<p>4.最后，save()方法触发action，将文件输出到指定文件中。</p>
</blockquote>
<pre><code><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Saves the content of the [[DataFrame]] at the specified path.</div><div class="line">   *</div><div class="line">   * @since 1.4.0</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">save</span></span>(path: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">this</span>.extraOptions += (<span class="string">"path"</span> -&gt; path)</div><div class="line">    save()</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</code></pre><p><img src="http://img.blog.csdn.net/20160418122518845" alt=""></p>
<h3 id="2-Spark-SQL通过JDBC操作Mysql"><a href="#2-Spark-SQL通过JDBC操作Mysql" class="headerlink" title="2. Spark SQL通过JDBC操作Mysql"></a>2. Spark SQL通过JDBC操作Mysql</h3><p>SparkSQL可以通过JDBC从传统关系型数据库中读写数据，读取数据后直接生成的是DataFrame，然后再加上借助于Spark内核的丰富的API来进行各种操作。 </p>
<p>不通过SparkSQL，直接通过RDD也可以操作MySQL。</p>
<p>【代码实战】</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JDBCDataSource</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">"local"</span>).</div><div class="line">                setAppName(<span class="string">"JDBCDataSource"</span>).</div><div class="line">                set(<span class="string">"spark.testing.memory"</span>, <span class="string">"2147480000"</span>);</div><div class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</div><div class="line">        SQLContext sqlContext = <span class="keyword">new</span> SQLContext(sc);</div><div class="line">        <span class="comment">// 方法1、</span></div><div class="line">        <span class="comment">/*Map&lt;String, String&gt; options = new HashMap&lt;String, String&gt;();</span></div><div class="line"></div><div class="line">        options.put("url", "jdbc:mysql://node05:3306/testdb");</div><div class="line">        options.put("driver", "com.mysql.jdbc.Driver");</div><div class="line">        options.put("user", "root");</div><div class="line">        options.put("password", "123");</div><div class="line">        options.put("dbtable", "student_info");</div><div class="line">        DataFrame studentInfosDF = sqlContext.read().format("jdbc").</div><div class="line">                options(options).load();</div><div class="line">        options.put("dbtable", "student_score");</div><div class="line">        DataFrame studentScoresDF = sqlContext.read().format("jdbc").</div><div class="line">                options(options).load();*/</div><div class="line"></div><div class="line">        <span class="comment">//方法二、</span></div><div class="line">        DataFrameReader reader = sqlContext.read().format(<span class="string">"jdbc"</span>);</div><div class="line">        reader.option(<span class="string">"url"</span>, <span class="string">"jdbc:mysql://node05:3306/testdb"</span>);</div><div class="line">        reader.option(<span class="string">"driver"</span>, <span class="string">"com.mysql.jdbc.Driver"</span>);</div><div class="line">        reader.option(<span class="string">"user"</span>, <span class="string">"root"</span>);</div><div class="line">        reader.option(<span class="string">"password"</span>, <span class="string">"123"</span>);</div><div class="line">        reader.option(<span class="string">"dbtable"</span>, <span class="string">"student_info"</span>);</div><div class="line">        DataFrame studentInfosDF = reader.load();</div><div class="line"></div><div class="line">        reader.option(<span class="string">"dbtable"</span>, <span class="string">"student_score"</span>);</div><div class="line">        DataFrame studentScoresDF = reader.load();</div><div class="line">        studentInfosDF.registerTempTable(<span class="string">"studentInfos"</span>);</div><div class="line">        studentScoresDF.registerTempTable(<span class="string">"studentScores"</span>);</div><div class="line">        String sql = <span class="string">"SELECT studentInfos.name,age,score "</span></div><div class="line">                + <span class="string">"		FROM studentInfos JOIN studentScores"</span></div><div class="line">                + <span class="string">"		 ON (studentScores.name = studentInfos.name)"</span></div><div class="line">                + <span class="string">"	 WHERE studentScores.score &gt; 90"</span>;</div><div class="line">        DataFrame sql2 = sqlContext.sql(sql);</div><div class="line">        sql2.show();</div><div class="line">        sql2.javaRDD().foreach(<span class="keyword">new</span> VoidFunction&lt;Row&gt;() &#123;</div><div class="line"></div><div class="line">            <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</div><div class="line"></div><div class="line">            <span class="meta">@Override</span></div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">call</span><span class="params">(Row row)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">                String sql = <span class="string">"insert into good_student_info values("</span> + <span class="string">"'"</span> </div><div class="line">                        + String.valueOf(row.getString(<span class="number">0</span>)) + <span class="string">"',"</span></div><div class="line">                        + Integer.valueOf(String.valueOf(row.get(<span class="number">1</span>))) + <span class="string">","</span></div><div class="line">                        + Integer.valueOf(String.valueOf(row.get(<span class="number">2</span>))) + <span class="string">")"</span>;</div><div class="line"></div><div class="line">                Class.forName(<span class="string">"com.mysql.jdbc.Driver"</span>);</div><div class="line"></div><div class="line">                Connection conn = <span class="keyword">null</span>;</div><div class="line">                Statement stmt = <span class="keyword">null</span>;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    conn = DriverManager.getConnection(</div><div class="line">                            <span class="string">"jdbc:mysql://node05:3306/testdb"</span>,</div><div class="line">                            <span class="string">"root"</span>, <span class="string">"123"</span>);</div><div class="line">                    stmt = conn.createStatement();</div><div class="line">                    stmt.executeUpdate(sql);</div><div class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                    <span class="keyword">if</span> (stmt != <span class="keyword">null</span>) &#123;</div><div class="line">                        stmt.close();</div><div class="line">                    &#125;</div><div class="line">                    <span class="keyword">if</span> (conn != <span class="keyword">null</span>) &#123;</div><div class="line">                        conn.close();</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;);</div><div class="line">        <span class="comment">/**</span></div><div class="line">         * 将SparkContext 关闭，释放资源</div><div class="line">         */</div><div class="line">        sc.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>【结果展示】</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">+-------+---+-----+</div><div class="line">|   name|age|score|</div><div class="line">+-------+---+-----+</div><div class="line">|   lisi| <span class="number">15</span>|   <span class="number">91</span>|</div><div class="line">|wangwu | <span class="number">20</span>|  <span class="number">100</span>|</div><div class="line">+-------+---+-----+</div></pre></td></tr></table></figure>
</code></pre><blockquote>
<p>在实际的企业级开发环境中我们如果数据库中数据规模特别大，例如10亿条数据，此时采用传统的db 去处理的话，一般需要对数据分成很多批次处理例如分成100批（首受限于单台server的处理能力）且实际处理可能会非常复杂，通过传统的J2ee 等基石很难或者很不方便实现处理方法，此时使用sparksql获得数数据库中的数据并进行分布式处理就可以非常好的解决该问题，但是sparksql 加载数据需要时间，所以一边会在sparksql和db 之间加一个缓冲层例如中间使用redis，可以把spark的处理速度提高甚至45倍。</p>
</blockquote>
<h3 id="3-Spark-SQL操作Hive数据源"><a href="#3-Spark-SQL操作Hive数据源" class="headerlink" title="3. Spark SQL操作Hive数据源"></a>3. Spark SQL操作Hive数据源</h3><blockquote>
<p>数据源：/root/resource/student_infos和/root/resource/student/student_scores两个文件。</p>
</blockquote>
<p>注：student_info和student_scores的文件内容以Tab键为分隔符。</p>
<p>【代码实战】</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HiveDataSource</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf()</div><div class="line">                .setAppName(<span class="string">"HiveDataSource"</span>);</div><div class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</div><div class="line">        <span class="comment">//是SQLContext的子类。</span></div><div class="line">        SQLContext hiveContext = <span class="keyword">new</span> HiveContext(sc);</div><div class="line">        <span class="comment">//删除hive中的student_infos表</span></div><div class="line">        hiveContext.sql(<span class="string">"DROP TABLE IF EXISTS student_infos"</span>);</div><div class="line"></div><div class="line">        <span class="comment">//在hive中创建student_infos表</span></div><div class="line">        hiveContext.sql(<span class="string">"CREATE TABLE IF NOT EXISTS student_infos "</span></div><div class="line">                + <span class="string">"(name STRING, age INT) "</span></div><div class="line">                + <span class="string">"row format delimited fields terminated by '\t'"</span>);</div><div class="line">        hiveContext.sql(<span class="string">"LOAD DATA "</span></div><div class="line">                + <span class="string">"LOCAL INPATH '/root/resource/student_infos' "</span></div><div class="line">                + <span class="string">"INTO TABLE student_infos"</span>);</div><div class="line">        hiveContext.sql(<span class="string">"DROP TABLE IF EXISTS student_scores"</span>);</div><div class="line">        hiveContext.sql(<span class="string">"CREATE TABLE IF NOT EXISTS student_scores "</span></div><div class="line">                + <span class="string">"(name STRING, score INT) "</span></div><div class="line">                + <span class="string">"row format delimited fields terminated by '\t'"</span>);</div><div class="line">        hiveContext.sql(<span class="string">"LOAD DATA "</span></div><div class="line">                + <span class="string">"LOCAL INPATH '/root/resource/student_scores'"</span></div><div class="line">                + <span class="string">"INTO TABLE student_scores"</span>);</div><div class="line">        DataFrame goodStudentsDF = hiveContext.sql(<span class="string">"SELECT si.name, "</span></div><div class="line">                + <span class="string">"si.age, ss.score "</span></div><div class="line">                + <span class="string">"FROM student_infos si "</span></div><div class="line">                + <span class="string">"JOIN student_scores ss ON si.name=ss.name "</span></div><div class="line">                + <span class="string">"WHERE ss.score&gt;=80"</span>);</div><div class="line"></div><div class="line">        hiveContext.sql(<span class="string">"USE result"</span>);</div><div class="line">        hiveContext.sql(<span class="string">"DROP TABLE IF EXISTS good_student_infos"</span>);</div><div class="line">        <span class="comment">//通过saveAsTable创建一张Hive Managed Table，</span></div><div class="line">        <span class="comment">//数据放在什么地方、元数据都是Hive管理的</span></div><div class="line">        goodStudentsDF.write().saveAsTable(<span class="string">"good_student_infos"</span>);</div><div class="line">        <span class="comment">//使用HivewContext的Table方法可以直接</span></div><div class="line">        <span class="comment">//去读Hive中的Table并生成DaraFrame</span></div><div class="line">        Row[] goodStudentRows = hiveContext.table(</div><div class="line">                <span class="string">"good_student_infos"</span>)</div><div class="line">                .collect();</div><div class="line">        <span class="keyword">for</span>(Row goodStudentRow : goodStudentRows) &#123;</div><div class="line">            System.out.println(goodStudentRow);</div><div class="line">        &#125;</div><div class="line">        sc.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><font color="blue">将上面的java代码打包jar,上传到liunx文件目录下。</font>

<blockquote>
<p>通过./spark-submit –master spark://node03:7077 ~/HiveDataSource.jar 命令来执行</p>
</blockquote>
<font color="red"><b>【报错】</b></font>

<pre><code>`
java.lang.IllegalArgumentException: java.net.UnknownHostException: scc
at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374)
at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312)
at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178)
`
</code></pre><blockquote>
<p>需要将HADOOP_HOME/etc/hadoop下的hdfs-site.xml拷贝到SPARK_HOME/conf下。</p>
</blockquote>
<p>【结果展示】</p>
<p><img src="http://a3.qpic.cn/psb?/V12DoSDy3E1yI8/t3ehiliZd3REbzq7vvCudql8zJ1MNYt4xmcPc*Wdoys!/b/dB8BAAAAAAAA&amp;bo=pgL1AAAAAAADB3M!&amp;rf=viewer_4" alt=""></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Spark学习总结/" rel="tag"># Spark学习总结</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/04/Spark/sparksql与dataframe/" rel="next" title="Spark学习笔记——SparkSQL与DataFrame原理解析与实现">
                <i class="fa fa-chevron-left"></i> Spark学习笔记——SparkSQL与DataFrame原理解析与实现
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/03/05/Spark/spark算子/" rel="prev" title="Spark学习笔记——Spark算子总结及案例">
                Spark学习笔记——Spark算子总结及案例 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2017/03/05/Spark/sparksql/"
           data-title="Spark学习笔记——Spark SQL的操作实例" data-url="http://yoursite.com/2017/03/05/Spark/sparksql/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="QDU-scc" />
          <p class="site-author-name" itemprop="name">QDU-scc</p>
           
              <p class="site-description motion-element" itemprop="description">一个有梦想的CS小白</p>
          
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">44</span>
                <span class="site-state-item-name">Artikel</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">Kategorien</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">Tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Spark-SQL数据加载和保存"><span class="nav-number">1.</span> <span class="nav-text">1. Spark SQL数据加载和保存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Spark-SQL通过JDBC操作Mysql"><span class="nav-number">2.</span> <span class="nav-text">2. Spark SQL通过JDBC操作Mysql</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Spark-SQL操作Hive数据源"><span class="nav-number">3.</span> <span class="nav-text">3. Spark SQL操作Hive数据源</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">QDU-scc</span>
</div>


<div class="powered-by">
  Erstellt mit  <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"andone1cc"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  













  
  

  

  

  

  


  

</body>
</html>
